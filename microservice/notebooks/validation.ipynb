{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Ba5rdJppTxOx",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a7330696-b347-44d8-c65c-31308678a75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/165.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/725.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.4/725.4 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTd3Sq1NvwwB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "LlEIHLCbYFs7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b0426b31-e8e8-4d59-e776-9c55e6034c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.24.10 (from PyMuPDF)\n",
      "  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMG57p3bYGqw",
    "outputId": "2d405f61-3dd1-4662-b930-64c1326c1a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "HFmFucTm4v8S"
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from google.colab import drive\n",
    "from transformers import pipeline\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "9z2vexqbYG5P"
   },
   "outputs": [],
   "source": [
    "def extract_pdf_data(pdf_file_path):\n",
    "    # Initialize an empty list to hold rows of extracted data\n",
    "    rows = []\n",
    "\n",
    "    # Open the PDF and extract data\n",
    "    with pdfplumber.open(pdf_file_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "\n",
    "            # If text exists, add it to the rows list\n",
    "            if text:\n",
    "                # Split the text into lines and treat each line as a row\n",
    "                lines = text.split('\\n')\n",
    "                for line in lines:\n",
    "                    rows.append(f\"Page {page_num + 1}: {line}\")\n",
    "\n",
    "            # Extract tables (if any)\n",
    "            table = page.extract_table()\n",
    "            if table:\n",
    "                for row in table:\n",
    "                    rows.append(f\"Page {page_num + 1} (Table): \" + \", \".join([str(cell) if cell else \"\" for cell in row]))\n",
    "\n",
    "    return rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "UqwvLpuFVcPx"
   },
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al_Lfs6TC1RF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "LNoC3LpGVd6A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "JFD0zS6ldfpg"
   },
   "outputs": [],
   "source": [
    "def data_extract(text):\n",
    "  model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "  response = model.generate_content(f\"Extract just the medical results of the patient from {text} and return it as simple text\")\n",
    "  return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "t_77vuYYY7wC"
   },
   "outputs": [],
   "source": [
    "def redact_sensitive_data(rows):\n",
    "    # Sending the row to the Gemini model for content generation (anonymization)\n",
    "    redacted_text=[]\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(f\"Replace people's names, phone numbers, any addresses and email id with [REDACTED] from {rows} do not add any more additional information\")\n",
    "    res = response.text\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxrR4vRUqeMZ",
    "outputId": "400ab8c1-3645-4022-9b9e-421b4ec63e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "def anonymise(pdf_file_path):\n",
    "  raw_text=extract_pdf_data(pdf_file_path)\n",
    "  extracted= data_extract(raw_text)\n",
    "  redacted = redact_sensitive_data(extracted)\n",
    "  return extracted\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_file = '/content/drive/My Drive/input.pdf'#input pdf file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "H0UlwgzMy3Ah"
   },
   "outputs": [],
   "source": [
    "def is_medical_data(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"medical-ner-proj/bert-medical-ner-proj\")\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\"medical-ner-proj/bert-medical-ner-proj\")\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract predicted labels\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "    labels = [model.config.id2label[pred.item()] for pred in predictions[0]]\n",
    "\n",
    "    # Pair tokens with their predictions and check for medical entities\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if label != 'O':  # If the label is not 'O', it means it's a medical entity\n",
    "            return True  # Medical data validated\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "2n9TAssF4bkc",
    "outputId": "f6bc2c4b-41cb-48de-b719-17d013ecf966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Medical Results:\n",
      "\n",
      "**Hb (Haemoglobin):** 15.0 gm/dl (M:13-18, F:11-16, Infant:14-20)\n",
      "**Erythrocytes:** 5.3 millions / cu.mm (4.5-5.5)\n",
      "**Leukocytes:** 8700 Cell/c.mm (4000-11000)\n",
      "**Neutrophils:** 62% (40-75)\n",
      "**Lymphocytes:** 34 (20-45)\n",
      "**Monocytes:** 02% (1-6)\n",
      "**Eosinophils:** 02 (1-8)\n",
      "**Basophils:** 00% (0-1)\n",
      "**ESR (Erythrocyte Sedimentation Rate):** 10 mm (0-15)\n",
      "**MP (Malaria Parasites):** NOT FOUND \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "pdf_summary=\"\"\n",
    "\n",
    "def file_validation_output(input_pdf):\n",
    "    text = anonymise(pdf_file)\n",
    "    print(text)\n",
    "    # Load the summarization pipeline\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "    # Summarize the text\n",
    "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "\n",
    "    if(is_medical_data(summary[0]['summary_text'])):\n",
    "      pdf_summary=summary[0]['summary_text']\n",
    "      return True,pdf_summary\n",
    "    else:\n",
    "      print(\"File shared does not contain medical data\")\n",
    "      return (False,)\n",
    "\n",
    "var = file_validation_output(pdf_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hF8SI7tD_RnB",
    "outputId": "92857bd7-96d0-4395-c2d1-b8b99cf4102f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hb (Haemoglobin):** 15.0 gm/dl (M:13-18, F:11-16, Infant:14-20) Erythrocytes:** 5.3 millions /'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_summary = var[1]\n",
    "file_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "5vqoSIiIvmdT",
    "outputId": "fe644a98-0b43-4e04-fb94-5516db582fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Hb(Haemoglobin) gm/dl M:13-18, F:11-16, Infant:14-20\n",
      "15.0\n",
      "TC (Total Count)\n",
      "Erythrocytes 5.3 millions / cu.mm 4.5-5.5\n",
      "Leukocytes 8700 Cell/c.mm 4000-11000\n",
      "DC (Differential Count)\n",
      "Neutrophils 62 % 40-75\n",
      "Lymphocytes 34 20-45\n",
      "Monocytes 02 % 1-6\n",
      "Eosinophils 02 1-8\n",
      "Basophils 00 % 0-1\n",
      "ESR (Erythrocyte Sedimentation Rate)\n",
      "1st Hr. (Westegren Method) 10 mm 0-15\n",
      "MP (Malaria Parasites) Thick & Thin NOT FOUND\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBuvBTxw_dVD"
   },
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASo62LJJ-Z0t",
    "outputId": "c2f4ac25-5e71-400a-b6ca-104597e887dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "a close up of a tube of blood on a blue cloth\n"
     ]
    }
   ],
   "source": [
    "image_caption = \"\"\n",
    "\n",
    "import requests\n",
    "def image_validity_checker(img_path):\n",
    "  API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "  headers = {\"Authorization\": \"\"}\n",
    "  with open(img_path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    if(is_medical_data(response.json()[0]['generated_text'])):\n",
    "      image_caption = response.json()[0]['generated_text']\n",
    "      return True,image_caption\n",
    "    else:\n",
    "      return (False,)import torch\n",
    "\n",
    "image_caption = image_validity_checker('/content/drive/My Drive/blood.jpg')[1]\n",
    "print(image_caption)\n",
    "# image_caption = query(img_path)#path to image\n",
    "# print(image_caption)\n",
    "# print(is_medical_data(image_caption[0]['generated_text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ev5jeunPw07k",
    "outputId": "944361e3-6087-426c-b3b6-eb2e1b07681c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Gh8-50TWuSeT"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Nfs7IHEIy2ud"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "bLLpmjrRy2xX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "dBIZZvrsy22d"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6HlL2g6y2z9",
    "outputId": "b0ea7803-0e4b-422a-8013-206a5cf7110a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",output_hidden_states=True)\n",
    "\n",
    "\n",
    "def get_sentence_vector(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    # Get the hidden states\n",
    "    hidden_states = outputs.hidden_states\n",
    "    # Take the embeddings from the last layer (or you can experiment with other layers)\n",
    "    last_layer_hidden_state = hidden_states[-1]\n",
    "\n",
    "    # Average over the token embeddings to get a single sentence vector\n",
    "    sentence_embedding = last_layer_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "    return sentence_embedding\n",
    "\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Flatten the vectors\n",
    "    vec1 = vec1.flatten()\n",
    "    vec2 = vec2.flatten()\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "# Example sentences\n",
    "# image_caption = \"This is a blood sample with white blood cells\" #image\n",
    "# pdf_summary = \"Erythrocytes 5.3 millions / cu.mm 4.5-5.5. Leukocytes 8700 Cell/c.mm 4000-11000. Neutrophils 62 % 40-75.\" #from text from pdf\n",
    "direct_input = \"This is a Blood test of a patient\" #from manually added information\n",
    "# print(\"Direct Input is :\",direct_input)\n",
    "# print(\"PDF Summary is: \",file_summary)\n",
    "# print(\"image caption is: \",image_caption)\n",
    "\n",
    "\n",
    "  # print(\"Similarity between sentence 1 and 2:\", similarity1)\n",
    "  # print(\"Similarity between sentence 1 and 3:\", similarity2)\n",
    "  # print(\"Similarity between sentence 2 and 3:\", similarity3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "wSAfFi13y243"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def combined_validation(image_caption,file_summary,direct_input):\n",
    "  # Get sentence vectors\n",
    "  vector1 = get_sentence_vector(image_caption)\n",
    "  vector2 = get_sentence_vector(file_summary)\n",
    "  vector3 = get_sentence_vector(direct_input)\n",
    "\n",
    "  # Calculate cosine similarity\n",
    "  similarity1 = cosine_similarity(vector1, vector2)\n",
    "  similarity2 = cosine_similarity(vector1, vector3)\n",
    "  similarity3 = cosine_similarity(vector2, vector3)\n",
    "\n",
    "  if similarity1 > 0.5 and similarity2 > 0.5 and similarity3 > 0.5:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCMTY3qSEpLm",
    "outputId": "e31c35a0-9c8c-4578-da89-cc31253479aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_validation(image_caption,file_summary,direct_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Yq_T3jBy27V",
    "outputId": "31c9f70a-5dfd-4e27-e9c1-a746b675cd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between sentence 1 and 2: 0.85645413\n",
      "Similarity between sentence 1 and 3: 0.9240234\n",
      "Similarity between sentence 2 and 3: 0.81558347\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HdzIfq5Ny29y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "8Fdz_gXby3DC"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "P-wg3tGhzNqj"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "znz8NTyKzPis"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lARLyZejzSVR"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "5VbIlf_IzTuQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URnV-QMtzUtH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
